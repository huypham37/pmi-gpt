# ACTIVE MEMORY: Issue #27
## Link
https://github.com/huypham37/pmi-gpt/issues/27

## Parent
Sub-issue of #24 (replace MarkItDown with Docling)

## Context & Goal
After Docling extracts markdown from a document, the text is stored as `extractedText` on a `ContextDocument` object. This issue explores the full persistence lifecycle:
- Where is it written on disk?
- How is it loaded back?
- How does it reach Claude (prompt injection / retrieval)?
- Are there size/chunking considerations?

## Starting Points
- `apps/electron/src/main/ipc.ts` ‚Äî `CONTEXT_ADD_DOCUMENT` handler (the write path, ~line 2465)
- Search for: `getOrCreateContext`, `saveContext`, `loadContext`, `manifest`, `ProjectContext`
- `apps/electron/src/renderer/components/testcases/ProjectContextPanel.tsx` ‚Äî UI read path
- `apps/electron/src/shared/types.ts` ‚Äî `ContextDocument`, `ProjectContext` type definitions

## Findings

### Storage
- `extractedText` is stored **inline** inside `manifest.json` as a plain JSON string field on each `ContextDocument`.
- Path: `{workspace.rootPath}/context/manifest.json`
- Schema: `{ description: string, documents: ContextDocument[], updatedAt: number }`
- Original binary file is also copied to: `{workspace.rootPath}/context/docs/{uuid}_{filename}`

### Retrieval
- `getOrCreateContext(workspaceId)` reads and parses the entire `manifest.json` on each call ‚Äî no caching, no indexing.
- Called at the start of `TESTCASES_GENERATE` IPC handler (`ipc.ts:2353`).

### Injection into Claude
- Only used in **test case generation** (`TESTCASES_GENERATE`) ‚Äî not in main chat.
- `buildAugmentedPrompt()` in `wstg-prompt.ts:54` injects context as:
  ```
  d.extractedText.slice(0, 2000)  // ‚ö†Ô∏è hardcoded truncation per doc
  ```
- Appended as a `### Project Context` section in the user message sent to a hidden ACP session.

### Data Flow
```
extractWithDocling()
  ‚Üí extractedText (full markdown, potentially 50k+ chars)
  ‚Üí saved inline in manifest.json
  ‚Üí read back on TESTCASES_GENERATE
  ‚Üí sliced to first 2000 chars per doc
  ‚Üí injected into Claude prompt
```

### Key Gap ‚Äî Storage Strategy
**extractedText is stored inline in manifest.json** ‚Äî this is not the correct strategy. For large documents, embedding full markdown inside a JSON file bloats manifest.json and loads the entire content into memory on every `getOrCreateContext()` call, even when it's not needed.

Correct strategy: persist the `.md` file to disk alongside the original binary, and store only the file path reference in the manifest.

Target path: `~/.craft-agent/workspaces/{workspaceId}/context/docs/{uuid}_{filename}.md`

**2000-char truncation** ‚Äî removed (wstg-prompt.ts:54 fixed). Claude now receives full markdown. A TODO was added to add error handling when total document size exceeds the context window.

## Plan
- [x] Trace `saveContext()` ‚Äî manifest.json location confirmed
- [x] Trace retrieval ‚Äî full JSON read on each generate call
- [x] Find injection point ‚Äî `wstg-prompt.ts:54`, `slice(0, 2000)`
- [x] Identify size limit ‚Äî 2000 chars per doc, hardcoded
- [x] Document findings

## Priority
üî¥ High ‚Äî needed before further context layer decisions (chunking, retrieval, RAG)

## Progress Log
### 2026-02-18 Initialization
- Created as sub-issue of #24.
- Not started. Next: search for `saveContext` / `getOrCreateContext` in the codebase.

### 2026-02-18 Exploration Complete
- Traced full write path: `CONTEXT_ADD_DOCUMENT` ‚Üí `extractWithDocling` ‚Üí inline in `manifest.json`.
- Traced full read path: `TESTCASES_GENERATE` ‚Üí `getOrCreateContext` ‚Üí `buildAugmentedPrompt` ‚Üí `slice(0, 2000)`.
- Critical finding: 2000-char truncation per document regardless of content size.
- Next: decide on chunking / summarization strategy for large documents.
